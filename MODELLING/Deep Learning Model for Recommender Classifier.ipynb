{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Recommendation Classifier with Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Let's start by loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.getcwd()\n",
    "os.chdir(r'C:\\Users\\MAIN\\Desktop\\ML\\Internship SMinds\\Recommender')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset\n",
    "df = pd.read_csv(\"TripAdvReview.csv\", na_values=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data wangling and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title  Rating  Review_counts  \\\n",
      "0                            Vacation/Cottage Rental     5.0           85.0   \n",
      "1    Mistiso's Place Vacation Rentals- Purcell Suite     4.5          100.0   \n",
      "2  Toronto 4 Bedroom House Spacious Clean Beautif...     5.0           36.0   \n",
      "3                                   Our Sweet Escape     5.0           34.0   \n",
      "4    Walk to ocean from Lyons Cottage Rentals in PEI     4.5           48.0   \n",
      "\n",
      "             City               Province  \\\n",
      "0   Niagara Falls                Ontario   \n",
      "1          Nelson       British Columbia   \n",
      "2         Toronto                Ontario   \n",
      "3  Qualicum Beach       British Columbia   \n",
      "4        Stanhope   Prince Edward Island   \n",
      "\n",
      "                                             Reviews  \n",
      "0  1 \\nThis rental felt more like a well-appointe...  \n",
      "1  4 \\nI can't say enough about this beautiful an...  \n",
      "2  1 \\nback yard! Would recommend the rental for ...  \n",
      "3  3 \\nenjoyable. I have never stayed in a vacati...  \n",
      "4  2 \\nquiet morning as we woke up - perfect vaca...  \n"
     ]
    }
   ],
   "source": [
    "#remove extra columns and keep the necessary ones for analysis\n",
    "df = pd.DataFrame(df.drop(['Bubble_Count', 'Review_Count'], axis=1))\n",
    "df.columns\n",
    "print(df.head(n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove new line characters from variable columns\n",
    "df = df.replace(r'\\n',' ', regex=True)\n",
    "\n",
    "#remove the numbers in the review column\n",
    "df.Reviews = df.Reviews.str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fills the rating and Review_counts variable missing values with the mean and median respectively\n",
    "df = df.fillna({'Rating': df.Rating.median(), 'Review_counts': df.Review_counts.mean()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_counts</th>\n",
       "      <th>City</th>\n",
       "      <th>Province</th>\n",
       "      <th>Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vacation/Cottage Rental</td>\n",
       "      <td>5.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>This rental felt more like a well-appointed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mistiso's Place Vacation Rentals- Purcell Suite</td>\n",
       "      <td>4.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Nelson</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>I can't say enough about this beautiful and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Toronto 4 Bedroom House Spacious Clean Beautif...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>back yard! Would recommend the rental for a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Our Sweet Escape</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Qualicum Beach</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>enjoyable. I have never stayed in a vacation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Walk to ocean from Lyons Cottage Rentals in PEI</td>\n",
       "      <td>4.5</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Stanhope</td>\n",
       "      <td>Prince Edward Island</td>\n",
       "      <td>quiet morning as we woke up - perfect vacati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Best views in Nelson</td>\n",
       "      <td>5.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Nelson</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>to buy even the coffee filters! Maybe they s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shale Beach House, Blue Mountain Collingwood Ont.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>Blue Mountains</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>vacation spot! There are three levels and so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Paradise Vacation Rentals</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>North Bay</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>This has to be one of the best vacation places...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Downtown Toronto 4BR Townhouse</td>\n",
       "      <td>5.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>paint but you could forgive this slightly as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Les Rives du Sanctuaire</td>\n",
       "      <td>5.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>Mont Tremblant</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>spend majestic vacation . His place is large...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Inn Of The Sea Resort-Newly renovated, Oceanvi...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Ladysmith</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>This is one of the best private vacation ren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Enormous Riverfront 2 Bedroom Condo in the Hea...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>Quebec City</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>Dalhousie, I cannot recall a vacation rental...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Downtown Apartment in Historic Cabbagetown</td>\n",
       "      <td>5.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>Tony and Steve's Aberdeen rental was the per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Air-con 3 BR view suite for 6, w/ 50' 4K Smart TV</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Nanaimo</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>the windows because the entire house (bottom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Downtown Toronto Furnished VACATION Rental</td>\n",
       "      <td>4.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>rental! The location was an excellent and se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>By the Vines 3 Bedroom 2 Bath Wine Country Get...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>Niagara-on-the-Lake</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>recommend this house to everyone who wants a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SURFS UP OCEANFRONT</td>\n",
       "      <td>5.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>Nova Scotia</td>\n",
       "      <td>like a real home more than a rental. Peacefu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Tigh-na Clayoquot Vacation House Tofino BC</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Tofino</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>order. It was a perfect home for us to vacat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Howe Bay Beach House - PEI Oceanfront Vacation...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Souris</td>\n",
       "      <td>Prince Edward Island</td>\n",
       "      <td>rental enough. Whether a celebration with a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Beach House on Square Bay</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Spring Bay</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>Honestly the nicest vacation rental you coul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Lazy Dayz. Only 2 minutes from Picton Main Street</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Picton</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>very hospitable! The rental itself was a bea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Burgess Lookout Guest Cabin</td>\n",
       "      <td>5.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>Field</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>This is what other vacation rentals should a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Simcoe Pines, 4 Bdrm Luxury home with heated pool</td>\n",
       "      <td>5.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>Niagara-on-the-Lake</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>Simcoe Pines provided the perfect place for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SHORE LARK BY THE SEA 1 BEDROOM VACATION RENTA...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Petty Harbour</td>\n",
       "      <td>Newfoundland and Labrador</td>\n",
       "      <td>Beautiful updated rental in perfect conditio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>The Hoblet,15 min. from the brink of Niagara F...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>The Hoblet is a great vacation/ getaway spot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Stunning Secluded Oceanfront Island Home Near ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Lunenburg</td>\n",
       "      <td>Nova Scotia</td>\n",
       "      <td>I absolutely fell in love with this rental p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Kitsilano's best, unique Coach House, license#...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>Vancouver</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>to rent from. This is a vacation rental that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Beautiful Home on Chesterman Beach</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Tofino</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>vacation! Could not have been a better famil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Kate's Cove</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Murray Harbour</td>\n",
       "      <td>Prince Edward Island</td>\n",
       "      <td>the twinkle of stars at night all combine to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>69 Glaciers Reach this 2br home has a hot tub ...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Whistler</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>Trevor and company at AllSeason Vacation Ren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Country In The City private 1 &amp; 2 Bedroom Suite</td>\n",
       "      <td>5.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>The rental was a beautiful, clean, and roomy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Accommodation Vacation Rental West Shore Victoria</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>The bed was very comfortable and gave us a goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Big Rock Vacation Rental - 203</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Campbell River</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>We stayed at the Big Rock Vacation Rental in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Presidential Condo - 207 - SALE - HALF OFF CLE...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>This Vacation Rental was the second best thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Mini Resort mins to beach and downtown Peachland</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Peachland</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>friendly and a great host. I highly recommen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Pat's Country Home</td>\n",
       "      <td>5.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>lovely vacation there. It is peaceful, and c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Junior Presidential Condo - 110 - SALE - HALF ...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>vacation rentals and came up with this choic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Trenanthia Cottage (Hot Tub, Sauna, Games Room...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Gravenhurst</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>cottage was great because unlike other rentals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Far Horizons Luxury Vacation Home</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Montebello</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>Greg and Jen of Far Horizons surely ensured ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Luxury downtown condo, steps to Inner Harbor!!!</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>thought I would be spending part of a vacati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Cedar Ridge</td>\n",
       "      <td>4.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Whistler</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>We stayed at Cedar Ridge  for a family vacat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>The Crow's Nest Luxury Vacation Home In Trinit...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Trinity</td>\n",
       "      <td>Newfoundland and Labrador</td>\n",
       "      <td>equipped with every modern amenity you could h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Manitoulin Island Cottage Rental</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>South Baymouth</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>We go every year to John Anita's house rental ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Anglers Vacation Home</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Campbell River</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>unreservedly recommend this vacation rental. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Goose Cove Retreat</td>\n",
       "      <td>5.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>Trinity</td>\n",
       "      <td>Newfoundland and Labrador</td>\n",
       "      <td>vacation homes in Trinity before for less th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>OCEANFRONT BEACH HOUSE - Black Rock Beach House</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Ucluelet</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>Black Rock Beach House is a great place for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Bright, Cozy 1 bdrm apt. w/parking near Bluffs</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>fantastic vacation rental. I would definitel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>***LAKEFRONT COTTAGE RENTAL ON LAKE ST. CLAIR***</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Lakeshore</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>Hello Stacy and Ken, It was a true delight to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Blue Heron Cove c/w Algonquin Park Pass - 4yr ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Algonquin Provincial Park</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>company. This truly was one of the best fami...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Bright Condo Close to Beach, Golf &amp; Royal Roads</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>If you ever need to find a perfect example o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>grand-beach. ca Cabin Rental Manitoba grand beach</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Grand Marais</td>\n",
       "      <td>Manitoba</td>\n",
       "      <td>recommend this cabin to anyone looking for a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>La Belle Brise</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Cheticamp</td>\n",
       "      <td>Nova Scotia</td>\n",
       "      <td>I'm glad I booked this holiday rental it met...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Amberlea House; 5 bedroom w Heated Pool, Old Town</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Niagara-on-the-Lake</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>when we are on vacation.....If you go to the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>28 Glaciers Reach, this 2br home has a hot tub...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Whistler</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>find the rental unit. The unit is simply fur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Surf Shack - Cozy Digs with Hot Tub - 2 Min wa...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Tofino</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>make all the difference. We are frequent visi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Private Luxurious Penthouse suite. 2 Bedroom 2...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Canmore</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>were using. Nevertheless, we would definitel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>300' lakefront, 50+ acres, Sat TV, Family Frie...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Spring Bay</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>need for a family vacation and the location i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Absolutely Suite Vacation Rental</td>\n",
       "      <td>4.5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Oliver</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>We had a lovely time staying at Russell and Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Avalon, English Country home with heated pool</td>\n",
       "      <td>5.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Niagara-on-the-Lake</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>We have had ten wonderful summer vacations w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Red Bay Getaway</td>\n",
       "      <td>4.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Sauble Beach</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>unwind. Thanks for another memorable family ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  Rating  Review_counts  \\\n",
       "0                              Vacation/Cottage Rental     5.0           85.0   \n",
       "1      Mistiso's Place Vacation Rentals- Purcell Suite     4.5          100.0   \n",
       "2    Toronto 4 Bedroom House Spacious Clean Beautif...     5.0           36.0   \n",
       "3                                     Our Sweet Escape     5.0           34.0   \n",
       "4      Walk to ocean from Lyons Cottage Rentals in PEI     4.5           48.0   \n",
       "..                                                 ...     ...            ...   \n",
       "96   Private Luxurious Penthouse suite. 2 Bedroom 2...     5.0           32.0   \n",
       "97   300' lakefront, 50+ acres, Sat TV, Family Frie...     5.0           30.0   \n",
       "98                    Absolutely Suite Vacation Rental     4.5           16.0   \n",
       "99       Avalon, English Country home with heated pool     5.0           37.0   \n",
       "100                                    Red Bay Getaway     4.5           26.0   \n",
       "\n",
       "                    City               Province  \\\n",
       "0          Niagara Falls                Ontario   \n",
       "1                 Nelson       British Columbia   \n",
       "2                Toronto                Ontario   \n",
       "3         Qualicum Beach       British Columbia   \n",
       "4               Stanhope   Prince Edward Island   \n",
       "..                   ...                    ...   \n",
       "96               Canmore                Alberta   \n",
       "97            Spring Bay                Ontario   \n",
       "98                Oliver       British Columbia   \n",
       "99   Niagara-on-the-Lake                Ontario   \n",
       "100         Sauble Beach                Ontario   \n",
       "\n",
       "                                               Reviews  \n",
       "0      This rental felt more like a well-appointed ...  \n",
       "1      I can't say enough about this beautiful and ...  \n",
       "2      back yard! Would recommend the rental for a ...  \n",
       "3      enjoyable. I have never stayed in a vacation...  \n",
       "4      quiet morning as we woke up - perfect vacati...  \n",
       "..                                                 ...  \n",
       "96     were using. Nevertheless, we would definitel...  \n",
       "97    need for a family vacation and the location i...  \n",
       "98   We had a lovely time staying at Russell and Ch...  \n",
       "99     We have had ten wonderful summer vacations w...  \n",
       "100    unwind. Thanks for another memorable family ...  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop all missing values\n",
    "df.dropna(axis=0,how='any', inplace= True)\n",
    "df.head(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index=range(571)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(571, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Title            0\n",
       "Rating           0\n",
       "Review_counts    0\n",
       "City             0\n",
       "Province         0\n",
       "Reviews          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type :  <class 'pandas.core.series.Series'>\n",
      "Length of reviews:  571\n",
      "Review at index 6:\n",
      "    vacation spot! There are three levels and so each family got their very own\n",
      "Label of the review at Index 6:  5.0\n"
     ]
    }
   ],
   "source": [
    "# Let's understand the two lists: reviews (text_train) and their labels (y_train)\n",
    "print(\"Type : \",type(df.Reviews))\n",
    "print(\"Length of reviews: \",len(df.Reviews))\n",
    "print(\"Review at index 6:\\n \", df.Reviews[6])\n",
    "print(\"Label of the review at Index 6: \",df.Rating[6])\n",
    "# The ratings laels is a continous series of float numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter punctuations, stemming and stopwords\n",
    "corpus = []\n",
    "for i in range(len(df)):\n",
    "    review = re.sub('[^a-zA-Z0-9]', ' ', df['Reviews'][i])\n",
    "    review = review.lower()\n",
    "    tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "    stemmer = nltk.PorterStemmer()\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    tokens_list = tokenizer.tokenize(review)\n",
    "    tokens = []\n",
    "    for token in tokens_list:\n",
    "        tokens.append(lemmatizer.lemmatize(token))\n",
    "        stop_words = stopwords.words(\"english\")\n",
    "    filtered_words = [w for w in tokens if w not in stop_words]\n",
    "    review = ' '.join(filtered_words)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bag of Words model to convert corpus into X\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "cv.fit(corpus)\n",
    "key = list(cv.vocabulary_.keys())\n",
    "key.sort()\n",
    "X = pd.DataFrame(cv.transform(corpus).toarray(),columns = key)\n",
    "y = df.Rating\n",
    "\n",
    "#TF_IDF model to convert corpus into X\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "X2 = pd.DataFrame(tfidf.fit_transform(corpus).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Encoding for Categorical Target Variable\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lb = LabelEncoder()\n",
    "df['Rating'] = lb.fit_transform(df['Rating'])\n",
    "y=df.Rating\n",
    "Rating = df.Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    372\n",
       "5    149\n",
       "4     31\n",
       "3      8\n",
       "2      5\n",
       "0      4\n",
       "1      2\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Rating.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h4>We need to get unique words to determine the vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = df.Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Unique words: 1856\n"
     ]
    }
   ],
   "source": [
    "uniq_words=set()\n",
    "for doc in reviews:\n",
    "    for word in doc.split(\" \"):\n",
    "        uniq_words.add(word)\n",
    "vocab_size=len(uniq_words)\n",
    "print (\"Total Unique words:\",vocab_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Time to import Keras and tensorflow modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>We need to convert each of the words in the reviews to one-hot vectors. Below is the code to get integer indexes of the words for one hot vector. Note that we don't need to store all zeros as only the integer index for the word in a vector will have a value of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1501, 519, 1537, 992, 1649, 1713, 723, 238, 420, 1147, 1266]\n"
     ]
    }
   ],
   "source": [
    "# Integer encode the documents\n",
    "\n",
    "encoded_reviews = [one_hot(review, vocab_size) for review in reviews]\n",
    "print(encoded_reviews[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> We fix the maximum length to 100 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1713 1266  238 ...    0    0    0]\n",
      " [1501  519 1537 ...    0    0    0]\n",
      " [ 250   13 1362 ...    0    0    0]\n",
      " ...\n",
      " [1147 1456  258 ...    0    0    0]\n",
      " [1302 1834 1266 ...    0    0    0]\n",
      " [1304    0    0 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# pad documents to a max length of n words\n",
    "max_length = 100\n",
    "padded_reviews = pad_sequences(encoded_reviews, maxlen=max_length, padding='post')\n",
    "print(padded_reviews)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>We have completed our pre-processing, it is now time to build the neural network based classifier. We start by splitting the reviews into training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_rev=padded_reviews[0:1000]\n",
    "#train_lbls=Rating[0:1000]\n",
    "#test_rev=padded_reviews[1001:]\n",
    "#test_lbls=Rating[1001:]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_reviews,Rating,test_size=0.3, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Now we need to define the basics of model for neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 16)           29696     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 4803      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 34,510\n",
      "Trainable params: 34,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "# define the model\n",
    "model = Sequential()\n",
    "# Define the embedding matrix dimensions. Each vector is of 8 dimensions and there will be total of vocab_size vectors\n",
    "# The input length (window) is 100 words so the output from embedding layer will be a conactenated (flattened) vector of \n",
    "# 800 dimensions\n",
    "model.add(Embedding(vocab_size, 16, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=3, activation='relu'))\n",
    "model.add(Dense(units=2, activation='relu'))\n",
    "model.add(Dense(units=1, activation='relu'))\n",
    "# compile the model with stochastic gradient descent and binary cross entropy\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['acc'])\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1212 20:35:08.302711 20892 deprecation_wrapper.py:119] From C:\\Users\\MAIN\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "399/399 [==============================] - 0s 967us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 2/200\n",
      "399/399 [==============================] - 0s 73us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 3/200\n",
      "399/399 [==============================] - 0s 73us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 4/200\n",
      "399/399 [==============================] - 0s 73us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 5/200\n",
      "399/399 [==============================] - 0s 68us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 6/200\n",
      "399/399 [==============================] - 0s 73us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 7/200\n",
      "399/399 [==============================] - 0s 78us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 8/200\n",
      "399/399 [==============================] - 0s 75us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 9/200\n",
      "399/399 [==============================] - 0s 83us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 10/200\n",
      "399/399 [==============================] - 0s 75us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 11/200\n",
      "399/399 [==============================] - 0s 75us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 12/200\n",
      "399/399 [==============================] - 0s 80us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 13/200\n",
      "399/399 [==============================] - 0s 78us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 14/200\n",
      "399/399 [==============================] - 0s 88us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 15/200\n",
      "399/399 [==============================] - 0s 85us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 16/200\n",
      "399/399 [==============================] - 0s 78us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 17/200\n",
      "399/399 [==============================] - 0s 78us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 18/200\n",
      "399/399 [==============================] - 0s 78us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 19/200\n",
      "399/399 [==============================] - 0s 80us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 20/200\n",
      "399/399 [==============================] - 0s 70us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 21/200\n",
      "399/399 [==============================] - 0s 65us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 22/200\n",
      "399/399 [==============================] - 0s 70us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 23/200\n",
      "399/399 [==============================] - 0s 75us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 24/200\n",
      "399/399 [==============================] - 0s 75us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 25/200\n",
      "399/399 [==============================] - 0s 73us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 26/200\n",
      "399/399 [==============================] - 0s 78us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 27/200\n",
      "399/399 [==============================] - 0s 73us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 28/200\n",
      "399/399 [==============================] - 0s 78us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 29/200\n",
      "399/399 [==============================] - 0s 80us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 30/200\n",
      "399/399 [==============================] - 0s 98us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 31/200\n",
      "399/399 [==============================] - 0s 80us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 32/200\n",
      "399/399 [==============================] - 0s 78us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 33/200\n",
      "399/399 [==============================] - 0s 83us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 34/200\n",
      "399/399 [==============================] - 0s 70us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 35/200\n",
      "399/399 [==============================] - 0s 75us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 36/200\n",
      "399/399 [==============================] - 0s 80us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 37/200\n",
      "399/399 [==============================] - 0s 70us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 38/200\n",
      "399/399 [==============================] - 0s 78us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 39/200\n",
      "399/399 [==============================] - 0s 70us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 40/200\n",
      "399/399 [==============================] - 0s 80us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 41/200\n",
      "399/399 [==============================] - 0s 78us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 42/200\n",
      "399/399 [==============================] - 0s 73us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 43/200\n",
      "399/399 [==============================] - 0s 75us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 44/200\n",
      "399/399 [==============================] - 0s 80us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 45/200\n",
      "399/399 [==============================] - 0s 73us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 46/200\n",
      "399/399 [==============================] - 0s 75us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 47/200\n",
      "399/399 [==============================] - 0s 78us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 48/200\n",
      "399/399 [==============================] - 0s 88us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 49/200\n",
      "399/399 [==============================] - 0s 83us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 50/200\n",
      "399/399 [==============================] - 0s 73us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 51/200\n",
      "399/399 [==============================] - 0s 78us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 52/200\n",
      "399/399 [==============================] - 0s 68us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 53/200\n",
      "399/399 [==============================] - 0s 83us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 54/200\n",
      "399/399 [==============================] - 0s 78us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 55/200\n",
      "399/399 [==============================] - 0s 75us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 56/200\n",
      "399/399 [==============================] - 0s 75us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 57/200\n",
      "399/399 [==============================] - 0s 70us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 58/200\n",
      "399/399 [==============================] - 0s 68us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 59/200\n",
      "399/399 [==============================] - 0s 68us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 60/200\n",
      "399/399 [==============================] - 0s 73us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 61/200\n",
      "399/399 [==============================] - 0s 75us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 62/200\n",
      "399/399 [==============================] - 0s 98us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 63/200\n",
      "399/399 [==============================] - 0s 90us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 64/200\n",
      "399/399 [==============================] - 0s 73us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 65/200\n",
      "399/399 [==============================] - 0s 68us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 66/200\n",
      "399/399 [==============================] - 0s 73us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 67/200\n",
      "399/399 [==============================] - 0s 75us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 68/200\n",
      "399/399 [==============================] - 0s 75us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 69/200\n",
      "399/399 [==============================] - 0s 65us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 70/200\n",
      "399/399 [==============================] - 0s 73us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 71/200\n",
      "399/399 [==============================] - 0s 65us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 72/200\n",
      "399/399 [==============================] - 0s 73us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 73/200\n",
      "399/399 [==============================] - 0s 73us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 74/200\n",
      "399/399 [==============================] - 0s 73us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 75/200\n",
      "399/399 [==============================] - 0s 65us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 76/200\n",
      "399/399 [==============================] - 0s 73us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 77/200\n",
      "399/399 [==============================] - 0s 78us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 78/200\n",
      "399/399 [==============================] - 0s 78us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 79/200\n",
      "399/399 [==============================] - 0s 73us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 80/200\n",
      "399/399 [==============================] - ETA: 0s - loss: 90.2613 - acc: 0.0000e+ - 0s 65us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 81/200\n",
      "399/399 [==============================] - 0s 70us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 82/200\n",
      "399/399 [==============================] - 0s 75us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 83/200\n",
      "399/399 [==============================] - 0s 85us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 84/200\n",
      "399/399 [==============================] - 0s 78us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 85/200\n",
      "399/399 [==============================] - 0s 68us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 86/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 87/200\n",
      "399/399 [==============================] - 0s 68us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 88/200\n",
      "399/399 [==============================] - 0s 65us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 89/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 90/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 91/200\n",
      "399/399 [==============================] - 0s 65us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 92/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 93/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 94/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 95/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 96/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 97/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 98/200\n",
      "399/399 [==============================] - 0s 80us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 99/200\n",
      "399/399 [==============================] - 0s 88us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 100/200\n",
      "399/399 [==============================] - 0s 68us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 101/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 102/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 103/200\n",
      "399/399 [==============================] - 0s 65us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 104/200\n",
      "399/399 [==============================] - 0s 65us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 105/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 106/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 107/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 108/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 109/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 110/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 111/200\n",
      "399/399 [==============================] - 0s 65us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 112/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 113/200\n",
      "399/399 [==============================] - 0s 65us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 114/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 115/200\n",
      "399/399 [==============================] - 0s 70us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 116/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 117/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 118/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 119/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 120/200\n",
      "399/399 [==============================] - 0s 70us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 121/200\n",
      "399/399 [==============================] - 0s 68us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 122/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 123/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 124/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 125/200\n",
      "399/399 [==============================] - 0s 68us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 126/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 127/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 128/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 129/200\n",
      "399/399 [==============================] - 0s 58us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 130/200\n",
      "399/399 [==============================] - 0s 65us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 131/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 132/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 133/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 134/200\n",
      "399/399 [==============================] - 0s 65us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 135/200\n",
      "399/399 [==============================] - 0s 65us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 136/200\n",
      "399/399 [==============================] - 0s 88us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 137/200\n",
      "399/399 [==============================] - 0s 88us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 138/200\n",
      "399/399 [==============================] - 0s 85us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 139/200\n",
      "399/399 [==============================] - 0s 73us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 140/200\n",
      "399/399 [==============================] - 0s 83us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 141/200\n",
      "399/399 [==============================] - 0s 65us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 142/200\n",
      "399/399 [==============================] - 0s 58us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 143/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 144/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 145/200\n",
      "399/399 [==============================] - 0s 65us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 146/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 147/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 148/200\n",
      "399/399 [==============================] - ETA: 0s - loss: 86.5005 - acc: 0.0000e+ - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 149/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 150/200\n",
      "399/399 [==============================] - 0s 68us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 151/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 152/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 153/200\n",
      "399/399 [==============================] - 0s 70us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 154/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 155/200\n",
      "399/399 [==============================] - 0s 65us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 156/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 157/200\n",
      "399/399 [==============================] - 0s 68us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 158/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 159/200\n",
      "399/399 [==============================] - 0s 65us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 160/200\n",
      "399/399 [==============================] - 0s 68us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 161/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 162/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 163/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 165/200\n",
      "399/399 [==============================] - 0s 68us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 166/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 167/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 168/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 169/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 170/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 171/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 172/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 173/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 174/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 175/200\n",
      "399/399 [==============================] - 0s 58us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 176/200\n",
      "399/399 [==============================] - 0s 68us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 177/200\n",
      "399/399 [==============================] - 0s 88us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 178/200\n",
      "399/399 [==============================] - 0s 73us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 179/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 180/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 181/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 182/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 183/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 184/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 185/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 186/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 187/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 188/200\n",
      "399/399 [==============================] - 0s 65us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 189/200\n",
      "399/399 [==============================] - 0s 58us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 190/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 191/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 192/200\n",
      "399/399 [==============================] - 0s 65us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 193/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 194/200\n",
      "399/399 [==============================] - 0s 68us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 195/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 196/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 197/200\n",
      "399/399 [==============================] - 0s 68us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 198/200\n",
      "399/399 [==============================] - 0s 65us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 199/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: 88.2254 - acc: 0.0075\n",
      "Epoch 200/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: 88.2254 - acc: 0.0075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c519223a20>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model... there are few docs, so I am trying with batch_size=1, you can delete it for default batch \n",
    "#size or change it to a bigger number\n",
    "model.fit(X_train, y_train, epochs=200,batch_size=30, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Now, we shall evaluate our model against the test set that we kep separate earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 302us/step\n",
      "Accuracy: 0.581395\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 238us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.01      1.00      0.01         1\n",
      "           1       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         9\n",
      "           5       0.00      0.00      0.00        41\n",
      "           6       0.00      0.00      0.00       117\n",
      "\n",
      "   micro avg       0.01      0.01      0.01       172\n",
      "   macro avg       0.00      0.17      0.00       172\n",
      "weighted avg       0.00      0.01      0.00       172\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAIN\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\MAIN\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\MAIN\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "predictions = model.predict(X_test, batch_size=100, verbose=1)\n",
    "predictions_bool = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(classification_report(y_test, predictions_bool))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
